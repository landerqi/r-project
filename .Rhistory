setwd("E:/www.github.com/r-project")
install.packages("janeaustenr")
library(janeaustenr)
install.packages("dplyr")
install.packages("dplyr")
library(janeaustenr)
library(dplyr)
library(stringr)
library(dplyr)
library(janeaustenr)
library(dplyr)
library(stringr)
install.packages(c("lattice", "MASS", "Matrix", "mgcv", "openssl", "Rcpp", "survival"))
book
original_books <- austen_books() %>% group_by(book)
library(janeaustenr)
library(dplyr)
library(dplyr)
library(janeaustenr)
library(dplyr)
library(stringr)
detach("package:dplyr", unload=TRUE)
library("dplyr", lib.loc="E:/Program Files/R/R-3.5.1/library")
search()
stats::filter()
original_books <- austen_books() %>% group_by(book)
library(stringr)
original_books <- austen_books() %>% group_by(book)
original_books
original_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex('^chapter [\\divxlc]', re_case = TRUE)))) %>%
ungroup()
original_books
?cumsum
book
?group_by
head(mtcars)
austen_books()$book
head(austen_books()$book)
head(austen_books()$text)
original_books
tail(original_books)
?ungroup
original_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex('^chapter [\\divxlc]', ignore_case = TRUE)))) %>%
ungroup()
original_books
library(tidytext)
install.packages('tidytext')
library(tidytext)
tidy_books <- original_books %>% unnest_tokens(word, text); tidy_books
tidy_books %>% count(word, sort = TRUE)
library(tidytext)
tidy_books <- original_books %>%
unnest_tokens(word, text); tidy_books # word是列名，text是original_books中要分析的text列
tidy_books %>% count(word, sort = TRUE)
data(stop_words)
stop_words
tidy_books <- tidy_books %>%
anti_join(stop_words) # 删除停用词如：'the', 'of', 'to'
tidy_books %>% count(word, sort = TRUE)
tidy_books <- original_books %>%
unnest_tokens(word, text); tidy_books # word是列名，text是original_books中要分析的text列
head(tidy_books, 100)
tidy_books %>% count(word, sort = TRUE) #查找最常见的单词
tidy_books <- tidy_books %>%
anti_join(stop_words) # 删除停用词如：'the', 'of', 'to'
tidy_books %>% count(word, sort = TRUE) #查找最常见的单词
install.packages('ggplot2')
### 生成图表
library(ggplot2)
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
### 生成图表
library(ggplot2)
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
?ggplot
?aes
aes(mpg, wt)
aes(x = mpg ^ 2, y = wt / cyl)
ggplot(mpg, aes(displ, hwy)) + geom_point()
head(mpg)
?geom_point
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
reorder()
?reorder
reorder('12', '231321312')
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n))
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n))
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n))
?geom_col
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_bar() +
xlab(NULL) +
coord_flip()
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_bar() +
ylab(NULL) +
coord_flip()
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
?xlab
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
# xlab(NULL) +
coord_flip()
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
#xlab(NULL) +
coord_flip()
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
?coord_flip
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL)
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip() # x,y transform
install.packages('gutenbergr')
# gutenbergr包
library(gutenbergr)
hgwells <- gutenberg_download(c(35, 36, 5230, 159)) # 通过id下载4本小说
hgwells
tidy_hgwells <- hgwells %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
tidy_hgwells %>% count(word, sort = TRUE)
bronte <- gutenberg_download(c(1260, 768, 969, 9182, 767))
bronte
tidy_bronte <- bronte %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
tidy_bronte %>% count(word, sort = TRUE)
tidy_books %>% count(word, sort = TRUE) #查找最常见的单词
install.packages('tidyr')
install.packages("tidyr")
tidy_bronte %>% count(word, sort = TRUE)
original_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex('^chapter [\\divxlc]', ignore_case = TRUE)))) %>%
ungroup()
library(stringr)
original_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex('^chapter [\\divxlc]', ignore_case = TRUE)))) %>%
ungroup()
tidy_bronte %>% count(word, sort = TRUE)
# 整理jane austen的作品
### janeaustenr包中有jane austen的六本小说的电子文档
library(janeaustenr)
library(dplyr)
library(stringr)
original_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex('^chapter [\\divxlc]', ignore_case = TRUE)))) %>%
ungroup()
original_books
### 找出最常见的单词
library(tidytext)
tidy_books <- original_books %>%
unnest_tokens(word, text); tidy_books # word是列名，text是original_books中要分析的text列
data(stop_words)
tidy_books <- tidy_books %>%
anti_join(stop_words) # 删除停用词如：'the', 'of', 'to'
tidy_books %>% count(word, sort = TRUE) #查找最常见的单词
### 生成图表
library(ggplot2)
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip() # x,y transform
# gutenbergr包
library(gutenbergr)
hgwells <- gutenberg_download(c(35, 36, 5230, 159)) # 通过id下载4本小说
tidy_hgwells <- hgwells %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
tidy_hgwells %>% count(word, sort = TRUE)
bronte <- gutenberg_download(c(1260, 768, 969, 9182, 767))
tidy_bronte <- bronte %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
tidy_bronte %>% count(word, sort = TRUE)
hgwells
tidy_bronte %>% count(word, sort = TRUE)
bronte
